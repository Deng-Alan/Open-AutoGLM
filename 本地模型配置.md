# 本地模型部署指南

## 说明

Ollama 下载的模型主要用于聊天，而 AutoGLM 需要支持视觉理解的模型服务。你需要使用 vLLM 或 SGLang 来部署模型。

## 方案1：使用 vLLM（推荐）

### 1. 安装 vLLM
```bash
pip install vllm>=0.12.0
pip install -U transformers --pre
```

### 2. 下载模型文件
```bash
# 从 Hugging Face 下载
git lfs install
git clone https://huggingface.co/zai-org/AutoGLM-Phone-9B

# 或从 ModelScope 下载
git clone https://modelscope.cn/ZhipuAI/AutoGLM-Phone-9B.git
```

### 3. 启动模型服务
```bash
python -m vllm.entrypoints.openai.api_server \
  --served-model-name autoglm-phone-9b \
  --allowed-local-media-path / \
  --mm-encoder-tp-mode data \
  --mm_processor_cache_type shm \
  --mm_processor_kwargs "{\"max_pixels\":5000000}" \
  --max-model-len 25480 \
  --chat-template-content-format string \
  --limit-mm-per-prompt "{\"image\":10}" \
  --model /path/to/AutoGLM-Phone-9B \
  --port 8000
```

### 4. 使用本地服务
```bash
python main.py --base-url http://localhost:8000/v1 --model autoglm-phone-9b "打开设置"
```

## 方案2：使用智谱官方 API（简单）

如果你不想本地部署，可以继续使用智谱官方 API：

```bash
run_zhipu_autoglm.bat "打开设置"
```

## 系统要求（本地部署）

- NVIDIA GPU（建议 16GB+ 显存）
- 32GB+ 系统内存
- Python 3.10+
- CUDA 11.8+

## 建议优先使用智谱 API

除非你有特殊需求（如离线使用、数据隐私等），建议优先使用智谱官方 API：
- 无需本地硬件要求
- 响应更快
- 免维护